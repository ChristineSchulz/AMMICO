{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b25986d7",
   "metadata": {},
   "source": [
    "# Crop posts from social media posts images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8a5a491",
   "metadata": {},
   "source": [
    "Crop posts from social media posts images, to keep import text informations from social media posts images.\n",
    "We can set some manually cropped views from social media posts as reference for cropping the same type social media posts images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70ffb7e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-19T08:52:05.212484Z",
     "iopub.status.busy": "2023-10-19T08:52:05.212097Z",
     "iopub.status.idle": "2023-10-19T08:52:05.235617Z",
     "shell.execute_reply": "2023-10-19T08:52:05.234695Z"
    }
   },
   "outputs": [],
   "source": [
    "# Please ignore this cell: extra install steps that are only executed when running the notebook on Google Colab\n",
    "# flake8-noqa-cell\n",
    "import os\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    # we're running on colab\n",
    "    # first install pinned version of setuptools (latest version doesn't seem to work with this package on colab)\n",
    "    %pip install setuptools==61 -qqq\n",
    "    # install the moralization package\n",
    "    %pip install git+https://github.com/ssciwr/AMMICO.git -qqq\n",
    "\n",
    "    # prevent loading of the wrong opencv library\n",
    "    %pip uninstall -y opencv-contrib-python\n",
    "    %pip install opencv-contrib-python\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    if not os.path.isdir('/content/ref'):\n",
    "      !wget https://github.com/ssciwr/AMMICO/archive/refs/heads/ref-data.zip -q\n",
    "      !unzip -qq ref-data.zip -d . && mv -f AMMICO-ref-data/data/ref . && rm -rf AMMICO-ref-data ref-data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae02c45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-19T08:52:05.239274Z",
     "iopub.status.busy": "2023-10-19T08:52:05.239004Z",
     "iopub.status.idle": "2023-10-19T08:52:19.403192Z",
     "shell.execute_reply": "2023-10-19T08:52:19.401692Z"
    }
   },
   "outputs": [],
   "source": [
    "import ammico.cropposts as crpo\n",
    "import ammico.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import importlib_resources\n",
    "pkg = importlib_resources.files(\"ammico\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7b8127f",
   "metadata": {},
   "source": [
    "The cropping is carried out by finding reference images on the image to be cropped. If a reference matches a region on the image, then everything below the matched region is removed. Manually look at a reference and an example post with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d04d0e86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-19T08:52:19.408006Z",
     "iopub.status.busy": "2023-10-19T08:52:19.406974Z",
     "iopub.status.idle": "2023-10-19T08:52:20.372934Z",
     "shell.execute_reply": "2023-10-19T08:52:20.371818Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't convert object to 'str' for 'filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load ref view for cropping the same type social media posts images.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# substitute the below paths for your samples\u001b[39;00m\n\u001b[1;32m      3\u001b[0m path_ref \u001b[38;5;241m=\u001b[39m pkg \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mref-00.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m ref_view \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m RGB_ref_view \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(ref_view, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m15\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't convert object to 'str' for 'filename'"
     ]
    }
   ],
   "source": [
    "# load ref view for cropping the same type social media posts images.\n",
    "# substitute the below paths for your samples\n",
    "path_ref = pkg / \"data\" / \"ref\" / \"ref-00.png\"\n",
    "ref_view = cv2.imread(path_ref)\n",
    "RGB_ref_view = cv2.cvtColor(ref_view, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(10, 15))\n",
    "plt.imshow(RGB_ref_view)\n",
    "plt.show()\n",
    "\n",
    "path_post = pkg / \"data\" / \"test-crop-image.png\"\n",
    "view = cv2.imread(path_post)\n",
    "RGB_view = cv2.cvtColor(view, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(10, 15))\n",
    "plt.imshow(RGB_view)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49a11f61",
   "metadata": {},
   "source": [
    "You can now crop the image and check on the way that everything looks fine. `plt_match` will plot the matches on the image and below which line content will be cropped; `plt_crop` will plot the cropped text part of the social media post with the comments removed; `plt_image` will plot the image part of the social media post if applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71850d9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-19T08:52:20.377671Z",
     "iopub.status.busy": "2023-10-19T08:52:20.376920Z",
     "iopub.status.idle": "2023-10-19T08:52:20.413717Z",
     "shell.execute_reply": "2023-10-19T08:52:20.412742Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ref_view' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# crop a posts from reference view, check the cropping \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# this will only plot something if the reference is found on the image\u001b[39;00m\n\u001b[1;32m      3\u001b[0m crop_view \u001b[38;5;241m=\u001b[39m crpo\u001b[38;5;241m.\u001b[39mcrop_posts_from_refs(\n\u001b[0;32m----> 4\u001b[0m     [\u001b[43mref_view\u001b[49m], view, \n\u001b[1;32m      5\u001b[0m     plt_match\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, plt_crop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, plt_image\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ref_view' is not defined"
     ]
    }
   ],
   "source": [
    "# crop a posts from reference view, check the cropping \n",
    "# this will only plot something if the reference is found on the image\n",
    "crop_view = crpo.crop_posts_from_refs(\n",
    "    [ref_view], view, \n",
    "    plt_match=True, plt_crop=True, plt_image=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1929e549",
   "metadata": {},
   "source": [
    "Batch crop images from the image folder given in `crop_dir`. The cropped images will save in `save_crop_dir` folder with the same file name as the original file. The reference images with the items to match are provided in `ref_dir`.\n",
    "\n",
    "Sometimes the cropping will be imperfect, due to improper matches on the image. It is sometimes easier to first categorize the social media posts and then set different references in the reference folder `ref_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eef89291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-19T08:52:20.417159Z",
     "iopub.status.busy": "2023-10-19T08:52:20.416920Z",
     "iopub.status.idle": "2023-10-19T08:52:20.482153Z",
     "shell.execute_reply": "2023-10-19T08:52:20.481146Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No files found in ../ammico/data/ with pattern '['png', 'jpg', 'jpeg', 'gif', 'webp', 'avif', 'tiff']'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m ref_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../ammico/data/ref\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m save_crop_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/crop/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m files \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrop_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m ref_files \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mfind_files(path\u001b[38;5;241m=\u001b[39mref_dir, limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      8\u001b[0m crpo\u001b[38;5;241m.\u001b[39mcrop_media_posts(files, ref_files, save_crop_dir, plt_match\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, plt_crop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, plt_image\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/work/AMMICO/AMMICO/ammico/utils.py:134\u001b[0m, in \u001b[0;36mfind_files\u001b[0;34m(path, pattern, recursive, limit, random_seed)\u001b[0m\n\u001b[1;32m    131\u001b[0m     results\u001b[38;5;241m.\u001b[39mextend(_match_pattern(path, p, recursive\u001b[38;5;241m=\u001b[39mrecursive))\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo files found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with pattern \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpattern\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m random_seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     random\u001b[38;5;241m.\u001b[39mseed(random_seed)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No files found in ../ammico/data/ with pattern '['png', 'jpg', 'jpeg', 'gif', 'webp', 'avif', 'tiff']'"
     ]
    }
   ],
   "source": [
    "\n",
    "crop_dir = \"../ammico/data/\"\n",
    "ref_dir = \"../ammico/data/ref\"\n",
    "save_crop_dir = \"data/crop/\"\n",
    "\n",
    "files = utils.find_files(path=crop_dir,limit=10,)\n",
    "ref_files = utils.find_files(path=ref_dir, limit=100)\n",
    "\n",
    "crpo.crop_media_posts(files, ref_files, save_crop_dir, plt_match=True, plt_crop=False, plt_image=False)\n",
    "print(\"Batch cropping images done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b3c1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
