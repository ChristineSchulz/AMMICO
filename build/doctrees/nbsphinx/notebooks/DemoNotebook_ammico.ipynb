{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMMICO Demonstration Notebook\n",
    "With ammico, you can analyze text on images and image content at the same time. This is a demonstration notebook to showcase the capabilities of ammico.\n",
    "You can run this notebook on google colab or locally / on your own HPC resource. The first cell only runs on google colab; on all other machines, you need to create a conda environment first and install ammico from the Python Package Index using  \n",
    "```pip install ammico```  \n",
    "Alternatively you can install the development version from the GitHub repository  \n",
    "```pip install git+https://github.com/ssciwr/AMMICO.git```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T14:19:27.762405Z",
     "iopub.status.busy": "2023-11-13T14:19:27.761928Z",
     "iopub.status.idle": "2023-11-13T14:19:27.771092Z",
     "shell.execute_reply": "2023-11-13T14:19:27.770478Z"
    }
   },
   "outputs": [],
   "source": [
    "# if running on google colab\n",
    "# flake8-noqa-cell\n",
    "import os\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "    # update python version\n",
    "    # install setuptools\n",
    "    # %pip install setuptools==61 -qqq\n",
    "    # install ammico\n",
    "    %pip install git+https://github.com/ssciwr/ammico.git -qqq\n",
    "    # mount google drive for data and API key\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the ammico package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T14:19:27.774641Z",
     "iopub.status.busy": "2023-11-13T14:19:27.774089Z",
     "iopub.status.idle": "2023-11-13T14:19:39.223625Z",
     "shell.execute_reply": "2023-11-13T14:19:39.222818Z"
    }
   },
   "outputs": [],
   "source": [
    "import ammico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Read your data into AMMICO\n",
    "The ammico package reads in one or several input files given in a folder for processing. The user can select to read in all image files in a folder, to include subfolders via the `recursive` option, and can select the file extension that should be considered (for example, only \"jpg\" files, or both \"jpg\" and \"png\" files). For reading in the files, the ammico function `find_files` is used, with optional keywords:\n",
    "\n",
    "| input key | input type | possible input values |\n",
    "| --------- | ---------- | --------------------- |\n",
    "`path` | `str` | the directory containing the image files (defaults to the location set by environment variable `AMMICO_DATA_HOME`) |\n",
    "| `pattern` | `str\\|list` | the file extensions to consider (defaults to \"png\", \"jpg\", \"jpeg\", \"gif\", \"webp\", \"avif\", \"tiff\") |\n",
    "| `recursive` | `bool` | include subdirectories recursively (defaults to `True`) |\n",
    "| `limit` | `int` | maximum number of files to read (defaults to `20`, for all images set to `None` or `-1`) |\n",
    "| `random_seed` | `str` | the random seed for shuffling the images; applies when only a few images are read and the selection should be preserved (defaults to `None`) |\n",
    "\n",
    "The `find_files` function returns a nested dict that contains the file ids and the paths to the files and is empty otherwise. This dict is filled step by step with more data as each detector class is run on the data (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T14:19:39.228510Z",
     "iopub.status.busy": "2023-11-13T14:19:39.227498Z",
     "iopub.status.idle": "2023-11-13T14:19:39.232834Z",
     "shell.execute_reply": "2023-11-13T14:19:39.232204Z"
    }
   },
   "outputs": [],
   "source": [
    "image_dict = ammico.find_files(\n",
    "    path=\"data/\",\n",
    "    limit=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Inspect the input files using the graphical user interface\n",
    "A Dash user interface is to select the most suitable options for the analysis, before running a complete analysis on the whole data set. The options for each detector module are explained below in the corresponding sections; for example, different models can be selected that will provide slightly different results. This way, the user can interactively explore which settings provide the most accurate results. In the interface, the nested `image_dict` is passed through the `AnalysisExplorer` class. The interface is run on a specific port which is passed using the `port` keyword; if a port is already in use, it will return an error message, in which case the user should select a different port number. \n",
    "The interface opens a dash app inside the Jupyter Notebook and allows selection of the input file in the top left dropdown menu, as well as selection of the detector type in the top right, with options for each detector type as explained below. The output of the detector is shown directly on the right next to the image. This way, the user can directly inspect how updating the options for each detector changes the computed results, and find the best settings for a production run.\n",
    "\n",
    "Please note that for the Google Cloud Vision API (the TextDetector class) you need to set a key in order to process the images. This key is ideally set as an environment variable using for example\n",
    "```\n",
    "os.environ[\n",
    "    \"GOOGLE_APPLICATION_CREDENTIALS\"\n",
    "] = \"/content/drive/MyDrive/misinformation-data/misinformation-campaign-981aa55a3b13.json\"\n",
    "```\n",
    "where you place the key on your Google Drive if running on colab, or place it in a local folder on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T14:19:39.236174Z",
     "iopub.status.busy": "2023-11-13T14:19:39.235700Z",
     "iopub.status.idle": "2023-11-13T14:19:39.272090Z",
     "shell.execute_reply": "2023-11-13T14:19:39.271478Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8055/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f509191ba90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analysis_explorer = ammico.AnalysisExplorer(image_dict)\n",
    "analysis_explorer.run_server(port=8055)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Analyze all images\n",
    "After having selected the best options for each detector module from the interactive GUI, the analysis can now be run in production on all images in the data set. Depending on the size of the data set and the computing resources available, this can take some time. Please note that you need to have set your Google Cloud Vision API key for the TextDetector to run.\n",
    "The desired detector modules are called sequentially in any order, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T14:19:39.320039Z",
     "iopub.status.busy": "2023-11-13T14:19:39.319376Z",
     "iopub.status.idle": "2023-11-13T14:23:26.728783Z",
     "shell.execute_reply": "2023-11-13T14:23:26.727605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.0/en_core_web_md-3.7.0-py3-none-any.whl (42.8 MB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/42.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:23\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/42.8 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/42.8 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/42.8 MB\u001b[0m \u001b[31m156.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/42.8 MB\u001b[0m \u001b[31m171.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.4/42.8 MB\u001b[0m \u001b[31m171.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m31.4/42.8 MB\u001b[0m \u001b[31m169.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m38.5/42.8 MB\u001b[0m \u001b[31m166.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m168.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m168.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m168.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from en-core-web-md==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (1.10.13)\n",
      "Requirement already satisfied: jinja2 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (58.1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: packaging>=20.0 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (1.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (2.1.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: en-core-web-md\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed en-core-web-md-3.7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)art-cnn-12-6/resolve/a4f8f3e/config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)art-cnn-12-6/resolve/a4f8f3e/config.json: 100%|██████████| 1.80k/1.80k [00:00<00:00, 243kB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:   2%|▏         | 21.0M/1.22G [00:00<00:10, 111MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:   3%|▎         | 41.9M/1.22G [00:00<00:09, 130MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:   5%|▌         | 62.9M/1.22G [00:00<00:08, 138MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:   7%|▋         | 83.9M/1.22G [00:00<00:08, 136MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:   9%|▊         | 105M/1.22G [00:00<00:08, 127MB/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  10%|█         | 126M/1.22G [00:00<00:08, 131MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  12%|█▏        | 147M/1.22G [00:01<00:07, 135MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  14%|█▎        | 168M/1.22G [00:01<00:08, 131MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  15%|█▌        | 189M/1.22G [00:01<00:07, 134MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  17%|█▋        | 210M/1.22G [00:01<00:07, 132MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  19%|█▉        | 231M/1.22G [00:01<00:07, 136MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  21%|██        | 252M/1.22G [00:01<00:07, 137MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  22%|██▏       | 273M/1.22G [00:02<00:06, 136MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  24%|██▍       | 294M/1.22G [00:02<00:06, 142MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  26%|██▌       | 315M/1.22G [00:02<00:06, 148MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  27%|██▋       | 336M/1.22G [00:02<00:05, 152MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  29%|██▉       | 357M/1.22G [00:02<00:05, 154MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  31%|███       | 377M/1.22G [00:02<00:05, 146MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  33%|███▎      | 398M/1.22G [00:02<00:05, 139MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  34%|███▍      | 419M/1.22G [00:03<00:06, 129MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  36%|███▌      | 440M/1.22G [00:03<00:06, 124MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  38%|███▊      | 461M/1.22G [00:03<00:06, 119MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  39%|███▉      | 482M/1.22G [00:03<00:06, 122MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  41%|████      | 503M/1.22G [00:03<00:05, 128MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  43%|████▎     | 524M/1.22G [00:03<00:05, 129MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  45%|████▍     | 545M/1.22G [00:04<00:05, 117MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  46%|████▋     | 566M/1.22G [00:04<00:05, 122MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  48%|████▊     | 587M/1.22G [00:04<00:05, 121MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  50%|████▉     | 608M/1.22G [00:04<00:05, 121MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  51%|█████▏    | 629M/1.22G [00:04<00:04, 128MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  53%|█████▎    | 650M/1.22G [00:04<00:04, 136MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  55%|█████▍    | 671M/1.22G [00:05<00:03, 141MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  57%|█████▋    | 692M/1.22G [00:05<00:03, 144MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  58%|█████▊    | 713M/1.22G [00:05<00:03, 150MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  60%|██████    | 734M/1.22G [00:05<00:03, 149MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  62%|██████▏   | 755M/1.22G [00:05<00:03, 138MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  63%|██████▎   | 776M/1.22G [00:05<00:03, 138MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  65%|██████▌   | 797M/1.22G [00:05<00:03, 136MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  67%|██████▋   | 818M/1.22G [00:06<00:02, 144MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  69%|██████▊   | 839M/1.22G [00:06<00:02, 148MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  70%|███████   | 860M/1.22G [00:06<00:02, 146MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  72%|███████▏  | 881M/1.22G [00:06<00:02, 140MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  74%|███████▍  | 902M/1.22G [00:07<00:04, 69.3MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  75%|███████▌  | 923M/1.22G [00:07<00:03, 81.3MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  77%|███████▋  | 944M/1.22G [00:07<00:03, 92.5MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  79%|███████▉  | 965M/1.22G [00:07<00:02, 106MB/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  81%|████████  | 986M/1.22G [00:07<00:02, 114MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  82%|████████▏ | 1.01G/1.22G [00:07<00:01, 124MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  84%|████████▍ | 1.03G/1.22G [00:08<00:01, 134MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  86%|████████▌ | 1.05G/1.22G [00:08<00:01, 143MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  88%|████████▊ | 1.07G/1.22G [00:08<00:01, 150MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  89%|████████▉ | 1.09G/1.22G [00:08<00:00, 155MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  91%|█████████ | 1.11G/1.22G [00:08<00:00, 154MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  93%|█████████▎| 1.13G/1.22G [00:08<00:00, 155MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  94%|█████████▍| 1.15G/1.22G [00:08<00:00, 156MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  96%|█████████▌| 1.17G/1.22G [00:08<00:00, 154MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  98%|█████████▊| 1.20G/1.22G [00:10<00:00, 49.2MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin: 100%|█████████▉| 1.22G/1.22G [00:10<00:00, 60.2MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin: 100%|██████████| 1.22G/1.22G [00:10<00:00, 119MB/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)-6/resolve/a4f8f3e/tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)-6/resolve/a4f8f3e/tokenizer_config.json: 100%|██████████| 26.0/26.0 [00:00<00:00, 15.0kB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)bart-cnn-12-6/resolve/a4f8f3e/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)bart-cnn-12-6/resolve/a4f8f3e/vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 67.9MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)bart-cnn-12-6/resolve/a4f8f3e/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)bart-cnn-12-6/resolve/a4f8f3e/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 51.8MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)st-2-english/resolve/af0f99b/config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)st-2-english/resolve/af0f99b/config.json: 100%|██████████| 629/629 [00:00<00:00, 299kB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:   8%|▊         | 21.0M/268M [00:00<00:01, 135MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  16%|█▌        | 41.9M/268M [00:00<00:01, 126MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  23%|██▎       | 62.9M/268M [00:00<00:01, 115MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  31%|███▏      | 83.9M/268M [00:00<00:01, 118MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  39%|███▉      | 105M/268M [00:00<00:01, 119MB/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  47%|████▋     | 126M/268M [00:01<00:01, 118MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  55%|█████▍    | 147M/268M [00:01<00:00, 122MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  63%|██████▎   | 168M/268M [00:01<00:00, 126MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  70%|███████   | 189M/268M [00:01<00:00, 132MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  78%|███████▊  | 210M/268M [00:01<00:00, 134MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  86%|████████▌ | 231M/268M [00:01<00:00, 135MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  94%|█████████▍| 252M/268M [00:01<00:00, 139MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin: 100%|██████████| 268M/268M [00:02<00:00, 130MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin: 100%|██████████| 268M/268M [00:02<00:00, 127MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)sh/resolve/af0f99b/tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)sh/resolve/af0f99b/tokenizer_config.json: 100%|██████████| 48.0/48.0 [00:00<00:00, 24.7kB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)-sst-2-english/resolve/af0f99b/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)-sst-2-english/resolve/af0f99b/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 51.3MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)ll03-english/resolve/f2482bf/config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)ll03-english/resolve/f2482bf/config.json: 100%|██████████| 998/998 [00:00<00:00, 508kB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:   1%|          | 10.5M/1.33G [00:00<00:43, 30.3MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:   2%|▏         | 21.0M/1.33G [00:00<00:55, 23.8MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:   2%|▏         | 31.5M/1.33G [00:01<00:39, 33.3MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:   3%|▎         | 41.9M/1.33G [00:01<00:40, 31.6MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:   4%|▍         | 52.4M/1.33G [00:01<00:41, 30.6MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:   5%|▍         | 62.9M/1.33G [00:01<00:35, 36.1MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:   6%|▌         | 73.4M/1.33G [00:02<00:30, 41.0MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:   6%|▋         | 83.9M/1.33G [00:02<00:44, 27.8MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:   7%|▋         | 94.4M/1.33G [00:03<00:54, 22.7MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:   8%|▊         | 105M/1.33G [00:04<01:02, 19.6MB/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:   9%|▊         | 115M/1.33G [00:04<01:12, 16.8MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:   9%|▉         | 126M/1.33G [00:05<01:06, 18.1MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  10%|█         | 136M/1.33G [00:05<00:53, 22.6MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  11%|█         | 147M/1.33G [00:06<00:50, 23.5MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  12%|█▏        | 157M/1.33G [00:06<00:47, 25.0MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  13%|█▎        | 168M/1.33G [00:06<00:45, 25.4MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  13%|█▎        | 178M/1.33G [00:06<00:39, 29.5MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  14%|█▍        | 189M/1.33G [00:07<00:38, 29.4MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  15%|█▍        | 199M/1.33G [00:07<00:42, 26.5MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  16%|█▌        | 210M/1.33G [00:08<00:41, 27.2MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  17%|█▋        | 220M/1.33G [00:08<00:35, 31.8MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  17%|█▋        | 231M/1.33G [00:08<00:33, 32.5MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  18%|█▊        | 241M/1.33G [00:09<00:40, 27.3MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  19%|█▉        | 252M/1.33G [00:09<00:48, 22.1MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  20%|█▉        | 262M/1.33G [00:10<00:47, 22.6MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  20%|██        | 273M/1.33G [00:10<00:45, 23.6MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  21%|██        | 283M/1.33G [00:10<00:37, 27.8MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  22%|██▏       | 294M/1.33G [00:11<00:42, 24.4MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  23%|██▎       | 304M/1.33G [00:11<00:36, 27.9MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  24%|██▎       | 315M/1.33G [00:12<00:37, 26.9MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  24%|██▍       | 325M/1.33G [00:12<00:40, 25.1MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  25%|██▌       | 336M/1.33G [00:13<00:39, 25.2MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  26%|██▌       | 346M/1.33G [00:13<00:33, 29.2MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  27%|██▋       | 357M/1.33G [00:13<00:37, 25.9MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  28%|██▊       | 377M/1.33G [00:14<00:35, 27.3MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  29%|██▉       | 388M/1.33G [00:14<00:31, 30.2MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  30%|██▉       | 398M/1.33G [00:15<00:33, 27.8MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  31%|███       | 409M/1.33G [00:15<00:34, 27.2MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  31%|███▏      | 419M/1.33G [00:16<00:35, 25.8MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  32%|███▏      | 430M/1.33G [00:16<00:34, 26.6MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  33%|███▎      | 440M/1.33G [00:16<00:34, 25.6MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  34%|███▍      | 451M/1.33G [00:17<00:37, 23.7MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  35%|███▍      | 461M/1.33G [00:17<00:37, 23.4MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  35%|███▌      | 472M/1.33G [00:18<00:31, 27.4MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  36%|███▌      | 482M/1.33G [00:18<00:26, 31.8MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  37%|███▋      | 493M/1.33G [00:18<00:26, 32.1MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  38%|███▊      | 503M/1.33G [00:19<00:30, 27.2MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  39%|███▊      | 514M/1.33G [00:19<00:31, 26.0MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  39%|███▉      | 524M/1.33G [00:19<00:29, 27.0MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  40%|████      | 535M/1.33G [00:20<00:29, 27.1MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  41%|████      | 545M/1.33G [00:20<00:33, 23.5MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  42%|████▏     | 556M/1.33G [00:21<00:29, 26.4MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  42%|████▏     | 566M/1.33G [00:21<00:30, 25.2MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  43%|████▎     | 577M/1.33G [00:22<00:28, 26.4MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  44%|████▍     | 587M/1.33G [00:22<00:34, 21.7MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  45%|████▍     | 598M/1.33G [00:23<00:29, 24.7MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  46%|████▌     | 608M/1.33G [00:23<00:30, 23.7MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  46%|████▋     | 619M/1.33G [00:24<00:31, 22.4MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  47%|████▋     | 629M/1.33G [00:24<00:31, 22.7MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  48%|████▊     | 640M/1.33G [00:24<00:26, 26.2MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  49%|████▊     | 650M/1.33G [00:25<00:27, 25.0MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  50%|████▉     | 661M/1.33G [00:25<00:30, 22.2MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  50%|█████     | 671M/1.33G [00:26<00:31, 21.2MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  51%|█████     | 682M/1.33G [00:26<00:27, 23.5MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  52%|█████▏    | 692M/1.33G [00:27<00:27, 23.4MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  53%|█████▎    | 703M/1.33G [00:27<00:26, 24.2MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  53%|█████▎    | 713M/1.33G [00:28<00:28, 21.7MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  54%|█████▍    | 724M/1.33G [00:28<00:24, 24.9MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  55%|█████▌    | 734M/1.33G [00:28<00:23, 25.3MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  56%|█████▌    | 744M/1.33G [00:29<00:20, 28.2MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  57%|█████▋    | 755M/1.33G [00:29<00:25, 23.1MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  57%|█████▋    | 765M/1.33G [00:29<00:19, 28.6MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  58%|█████▊    | 776M/1.33G [00:30<00:19, 28.7MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  59%|█████▉    | 786M/1.33G [00:30<00:20, 26.8MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  60%|█████▉    | 797M/1.33G [00:31<00:22, 24.2MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  61%|██████    | 807M/1.33G [00:31<00:19, 27.6MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  61%|██████▏   | 818M/1.33G [00:31<00:18, 27.2MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  62%|██████▏   | 828M/1.33G [00:32<00:23, 21.7MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  63%|██████▎   | 839M/1.33G [00:33<00:23, 21.0MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  64%|██████▎   | 849M/1.33G [00:33<00:19, 24.8MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  64%|██████▍   | 860M/1.33G [00:33<00:20, 22.7MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  65%|██████▌   | 870M/1.33G [00:34<00:17, 26.4MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  66%|██████▌   | 881M/1.33G [00:34<00:22, 20.5MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  67%|██████▋   | 891M/1.33G [00:35<00:19, 22.6MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  68%|██████▊   | 902M/1.33G [00:35<00:17, 24.8MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  68%|██████▊   | 912M/1.33G [00:35<00:14, 28.2MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  69%|██████▉   | 923M/1.33G [00:36<00:14, 28.1MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  70%|██████▉   | 933M/1.33G [00:36<00:12, 33.4MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  71%|███████   | 944M/1.33G [00:36<00:13, 28.7MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  72%|███████▏  | 954M/1.33G [00:37<00:13, 28.4MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  72%|███████▏  | 965M/1.33G [00:37<00:12, 28.5MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  73%|███████▎  | 975M/1.33G [00:38<00:12, 27.7MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  74%|███████▍  | 986M/1.33G [00:38<00:11, 30.3MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  75%|███████▍  | 996M/1.33G [00:38<00:09, 34.5MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  75%|███████▌  | 1.01G/1.33G [00:38<00:10, 32.1MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  76%|███████▌  | 1.02G/1.33G [00:39<00:10, 31.2MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  77%|███████▋  | 1.03G/1.33G [00:39<00:12, 23.9MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  78%|███████▊  | 1.04G/1.33G [00:40<00:11, 25.7MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  79%|███████▊  | 1.05G/1.33G [00:40<00:12, 23.0MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  79%|███████▉  | 1.06G/1.33G [00:41<00:11, 23.8MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  80%|████████  | 1.07G/1.33G [00:41<00:12, 21.2MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  81%|████████  | 1.08G/1.33G [00:42<00:10, 23.7MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  82%|████████▏ | 1.09G/1.33G [00:42<00:10, 22.6MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  83%|████████▎ | 1.10G/1.33G [00:42<00:08, 27.0MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  83%|████████▎ | 1.11G/1.33G [00:43<00:08, 27.6MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  84%|████████▍ | 1.12G/1.33G [00:43<00:07, 28.4MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  85%|████████▍ | 1.13G/1.33G [00:44<00:09, 22.3MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  86%|████████▌ | 1.14G/1.33G [00:44<00:07, 24.9MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  86%|████████▋ | 1.15G/1.33G [00:45<00:07, 25.3MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  87%|████████▋ | 1.16G/1.33G [00:45<00:06, 25.1MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  88%|████████▊ | 1.17G/1.33G [00:45<00:06, 24.8MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  89%|████████▉ | 1.18G/1.33G [00:46<00:05, 27.9MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  90%|████████▉ | 1.20G/1.33G [00:46<00:05, 27.5MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  90%|█████████ | 1.21G/1.33G [00:46<00:04, 29.1MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  91%|█████████ | 1.22G/1.33G [00:47<00:04, 24.6MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  92%|█████████▏| 1.23G/1.33G [00:47<00:03, 29.6MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  93%|█████████▎| 1.24G/1.33G [00:48<00:03, 25.4MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  94%|█████████▎| 1.25G/1.33G [00:48<00:03, 27.3MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  94%|█████████▍| 1.26G/1.33G [00:48<00:02, 27.1MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  95%|█████████▌| 1.27G/1.33G [00:49<00:02, 28.8MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  96%|█████████▌| 1.28G/1.33G [00:49<00:01, 31.0MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  97%|█████████▋| 1.29G/1.33G [00:49<00:01, 28.1MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  97%|█████████▋| 1.30G/1.33G [00:50<00:01, 19.6MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  98%|█████████▊| 1.31G/1.33G [00:51<00:00, 24.1MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin:  99%|█████████▉| 1.32G/1.33G [00:51<00:00, 22.0MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin: 100%|█████████▉| 1.33G/1.33G [00:51<00:00, 25.9MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "pytorch_model.bin: 100%|██████████| 1.33G/1.33G [00:51<00:00, 25.7MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)sh/resolve/f2482bf/tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)sh/resolve/f2482bf/tokenizer_config.json: 100%|██████████| 60.0/60.0 [00:00<00:00, 33.6kB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)onll03-english/resolve/f2482bf/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)onll03-english/resolve/f2482bf/vocab.txt: 100%|██████████| 213k/213k [00:00<00:00, 59.3MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5' to file '/home/runner/.cache/pooch/3be32af6e4183fa0156bc33bda371147-retinaface.h5'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'https://github.com/chandrikadeb7/Face-Mask-Detection/raw/v1.0.0/mask_detector.model' to file '/home/runner/.cache/pooch/865b4b1e20f798935b70082440d5fb21-mask_detector.model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 1s 783ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'https://github.com/serengil/deepface_models/releases/download/v1.0/age_model_weights.h5' to file '/home/runner/.cache/pooch/39859d3331cd91ac06154cc306e1acc8-age_model_weights.h5'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'https://github.com/serengil/deepface_models/releases/download/v1.0/facial_expression_model_weights.h5' to file '/home/runner/.cache/pooch/dd5d5d6d8f5cecdc0fa6cb34d4d82d16-facial_expression_model_weights.h5'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'https://github.com/serengil/deepface_models/releases/download/v1.0/gender_model_weights.h5' to file '/home/runner/.cache/pooch/2e0d8fb96c5ee966ade0f3f2360f6478-gender_model_weights.h5'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'https://github.com/serengil/deepface_models/releases/download/v1.0/race_model_single_batch.h5' to file '/home/runner/.cache/pooch/382cb5446128012fa5305ddb9d608751-race_model_single_batch.h5'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 341ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 387ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 246ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 220ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 1s 696ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 200ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 238ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 358ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 101ms/step\n"
     ]
    }
   ],
   "source": [
    "for key in image_dict.keys():\n",
    "    image_dict[key] = ammico.TextDetector(image_dict[key], analyse_text=True).analyse_image()\n",
    "    image_dict[key] = ammico.EmotionDetector(image_dict[key]).analyse_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the computationally demanding `SummaryDetector`, it is best to initialize the model first and then analyze each image while passing the model explicitly. This can be done in a separate loop or in the same loop as for text and emotion detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T14:23:26.790699Z",
     "iopub.status.busy": "2023-11-13T14:23:26.790024Z",
     "iopub.status.idle": "2023-11-13T14:25:44.777039Z",
     "shell.execute_reply": "2023-11-13T14:25:44.772753Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)bert-base-uncased/resolve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)bert-base-uncased/resolve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 49.6MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)cased/resolve/main/tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)cased/resolve/main/tokenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 15.8kB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)rt-base-uncased/resolve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(…)rt-base-uncased/resolve/main/config.json: 100%|██████████| 570/570 [00:00<00:00, 308kB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0.00/2.50G [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5.08M/2.50G [00:00<00:50, 53.2MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 18.0M/2.50G [00:00<00:26, 102MB/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 30.7M/2.50G [00:00<00:22, 116MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 41.8M/2.50G [00:00<00:22, 116MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 52.9M/2.50G [00:00<00:24, 109MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 63.4M/2.50G [00:00<00:24, 105MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 73.8M/2.50G [00:00<00:24, 107MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 85.4M/2.50G [00:00<00:23, 111MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 98.6M/2.50G [00:00<00:21, 119MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 113M/2.50G [00:01<00:20, 127MB/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 127M/2.50G [00:01<00:19, 134MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 144M/2.50G [00:01<00:17, 145MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 159M/2.50G [00:01<00:16, 149MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 173M/2.50G [00:01<00:16, 150MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 188M/2.50G [00:01<00:16, 149MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 204M/2.50G [00:01<00:15, 156MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▊         | 219M/2.50G [00:01<00:18, 136MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 235M/2.50G [00:01<00:17, 143MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 249M/2.50G [00:01<00:16, 144MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 263M/2.50G [00:02<00:17, 141MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 276M/2.50G [00:02<00:17, 139MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█▏        | 291M/2.50G [00:02<00:16, 143MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 305M/2.50G [00:02<00:16, 144MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 320M/2.50G [00:02<00:15, 149MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 335M/2.50G [00:02<00:16, 139MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▎        | 350M/2.50G [00:02<00:16, 143MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 365M/2.50G [00:02<00:15, 148MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 380M/2.50G [00:02<00:15, 150MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 397M/2.50G [00:03<00:14, 159MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 412M/2.50G [00:03<00:14, 158MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 430M/2.50G [00:03<00:13, 166MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 446M/2.50G [00:03<00:14, 153MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 464M/2.50G [00:03<00:13, 163MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 481M/2.50G [00:03<00:12, 168MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 498M/2.50G [00:03<00:12, 171MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 514M/2.50G [00:03<00:14, 153MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 530M/2.50G [00:03<00:13, 158MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██▏       | 548M/2.50G [00:04<00:12, 166MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 564M/2.50G [00:04<00:12, 162MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 583M/2.50G [00:04<00:12, 170MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 599M/2.50G [00:04<00:13, 150MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 615M/2.50G [00:04<00:13, 154MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 630M/2.50G [00:04<00:13, 150MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 645M/2.50G [00:04<00:13, 153MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 660M/2.50G [00:04<00:13, 151MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▋       | 675M/2.50G [00:04<00:14, 138MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 688M/2.50G [00:05<00:16, 122MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 704M/2.50G [00:05<00:15, 125MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 718M/2.50G [00:05<00:14, 130MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 731M/2.50G [00:05<00:16, 115MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 744M/2.50G [00:05<00:16, 118MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 758M/2.50G [00:05<00:15, 125MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 774M/2.50G [00:05<00:13, 135MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 788M/2.50G [00:05<00:13, 140MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███▏      | 802M/2.50G [00:05<00:13, 135MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 816M/2.50G [00:06<00:13, 135MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 829M/2.50G [00:06<00:13, 136MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 843M/2.50G [00:06<00:15, 118MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▎      | 859M/2.50G [00:06<00:13, 130MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 874M/2.50G [00:06<00:12, 138MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▍      | 890M/2.50G [00:06<00:12, 145MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 904M/2.50G [00:06<00:13, 126MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 920M/2.50G [00:06<00:12, 137MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▋      | 934M/2.50G [00:07<00:16, 101MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 949M/2.50G [00:07<00:14, 114MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 961M/2.50G [00:07<00:14, 117MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 974M/2.50G [00:07<00:19, 86.2MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▊      | 990M/2.50G [00:07<00:15, 103MB/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 0.98G/2.50G [00:07<00:14, 113MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███▉      | 0.99G/2.50G [00:08<00:18, 85.8MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 1.00G/2.50G [00:08<00:24, 66.3MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 1.02G/2.50G [00:08<00:21, 72.8MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 1.03G/2.50G [00:08<00:18, 86.5MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 1.04G/2.50G [00:08<00:15, 102MB/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 1.06G/2.50G [00:08<00:15, 98.8MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 1.07G/2.50G [00:08<00:17, 87.0MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 1.08G/2.50G [00:09<00:16, 90.9MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▎     | 1.09G/2.50G [00:09<00:14, 102MB/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 1.11G/2.50G [00:09<00:13, 114MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▍     | 1.12G/2.50G [00:09<00:12, 117MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 1.13G/2.50G [00:09<00:12, 122MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 1.14G/2.50G [00:09<00:13, 108MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 1.16G/2.50G [00:09<00:12, 112MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 1.17G/2.50G [00:09<00:12, 111MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 1.18G/2.50G [00:10<00:12, 118MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 1.20G/2.50G [00:10<00:10, 139MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▊     | 1.22G/2.50G [00:10<00:09, 152MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 1.23G/2.50G [00:10<00:09, 144MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████▉     | 1.24G/2.50G [00:10<00:13, 97.9MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 1.26G/2.50G [00:10<00:12, 111MB/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 1.27G/2.50G [00:10<00:11, 116MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████▏    | 1.29G/2.50G [00:10<00:11, 118MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 1.30G/2.50G [00:11<00:09, 135MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 1.32G/2.50G [00:11<00:08, 145MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 1.34G/2.50G [00:11<00:08, 145MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 1.35G/2.50G [00:11<00:07, 155MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 1.37G/2.50G [00:11<00:07, 164MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 1.39G/2.50G [00:11<00:09, 133MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 1.40G/2.50G [00:11<00:08, 144MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 1.42G/2.50G [00:11<00:07, 155MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 1.44G/2.50G [00:11<00:07, 162MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 1.45G/2.50G [00:12<00:09, 125MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▊    | 1.47G/2.50G [00:12<00:10, 106MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 1.48G/2.50G [00:12<00:09, 112MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████▉    | 1.49G/2.50G [00:12<00:17, 61.3MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 1.51G/2.50G [00:13<00:13, 76.6MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 1.52G/2.50G [00:13<00:12, 82.7MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 1.53G/2.50G [00:13<00:12, 86.7MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 1.54G/2.50G [00:13<00:12, 81.5MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 1.56G/2.50G [00:13<00:10, 95.1MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 1.57G/2.50G [00:13<00:10, 99.2MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 1.58G/2.50G [00:13<00:09, 104MB/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 1.59G/2.50G [00:13<00:08, 109MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 1.60G/2.50G [00:13<00:08, 114MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 1.61G/2.50G [00:14<00:07, 121MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 1.63G/2.50G [00:14<00:07, 119MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 1.64G/2.50G [00:14<00:07, 120MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 1.65G/2.50G [00:14<00:07, 126MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▋   | 1.66G/2.50G [00:14<00:06, 131MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 1.68G/2.50G [00:14<00:06, 133MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 1.69G/2.50G [00:14<00:06, 136MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 1.70G/2.50G [00:14<00:07, 119MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 1.71G/2.50G [00:14<00:07, 115MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 1.73G/2.50G [00:15<00:06, 129MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████▉   | 1.75G/2.50G [00:15<00:05, 140MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 1.76G/2.50G [00:15<00:05, 147MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 1.78G/2.50G [00:15<00:05, 140MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 1.79G/2.50G [00:15<00:05, 146MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 1.81G/2.50G [00:15<00:04, 153MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 1.82G/2.50G [00:15<00:04, 149MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 1.84G/2.50G [00:15<00:04, 152MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 1.85G/2.50G [00:15<00:04, 144MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 1.86G/2.50G [00:16<00:05, 119MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▍  | 1.88G/2.50G [00:16<00:05, 125MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 1.89G/2.50G [00:16<00:05, 130MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 1.90G/2.50G [00:16<00:05, 120MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 1.92G/2.50G [00:16<00:05, 125MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 1.93G/2.50G [00:16<00:05, 117MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 1.94G/2.50G [00:16<00:05, 112MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 1.95G/2.50G [00:16<00:05, 106MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▊  | 1.97G/2.50G [00:17<00:04, 120MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 1.98G/2.50G [00:17<00:04, 130MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████▉  | 2.00G/2.50G [00:17<00:05, 102MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 2.01G/2.50G [00:17<00:04, 110MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 2.02G/2.50G [00:17<00:04, 107MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 2.03G/2.50G [00:17<00:04, 116MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 2.04G/2.50G [00:18<00:07, 66.1MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 2.06G/2.50G [00:18<00:06, 78.1MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 2.07G/2.50G [00:18<00:05, 87.6MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 2.08G/2.50G [00:18<00:04, 95.5MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▎ | 2.09G/2.50G [00:18<00:07, 63.1MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 2.10G/2.50G [00:18<00:05, 76.5MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▍ | 2.12G/2.50G [00:18<00:04, 89.5MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 2.13G/2.50G [00:18<00:03, 103MB/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 2.15G/2.50G [00:19<00:03, 119MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▋ | 2.16G/2.50G [00:19<00:02, 134MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 2.18G/2.50G [00:19<00:02, 145MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 2.20G/2.50G [00:19<00:02, 152MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 2.21G/2.50G [00:19<00:02, 154MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 2.23G/2.50G [00:19<00:01, 153MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 2.24G/2.50G [00:19<00:01, 156MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 2.26G/2.50G [00:19<00:01, 140MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 2.27G/2.50G [00:19<00:01, 132MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 2.28G/2.50G [00:20<00:02, 113MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 2.30G/2.50G [00:20<00:01, 127MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 2.31G/2.50G [00:20<00:01, 124MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 2.32G/2.50G [00:20<00:01, 123MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 2.34G/2.50G [00:20<00:01, 131MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 2.35G/2.50G [00:20<00:02, 72.0MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▍| 2.37G/2.50G [00:21<00:01, 87.2MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 2.38G/2.50G [00:21<00:01, 103MB/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 2.39G/2.50G [00:21<00:01, 112MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 2.41G/2.50G [00:21<00:01, 102MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 2.42G/2.50G [00:21<00:00, 118MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 2.44G/2.50G [00:21<00:00, 131MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 2.45G/2.50G [00:21<00:00, 101MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▊| 2.47G/2.50G [00:21<00:00, 110MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 2.48G/2.50G [00:22<00:00, 118MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████▉| 2.49G/2.50G [00:22<00:00, 126MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 2.50G/2.50G [00:22<00:00, 121MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0.00/1.35G [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 10.0M/1.35G [00:00<00:13, 104MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 23.4M/1.35G [00:00<00:11, 125MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 35.3M/1.35G [00:00<00:12, 114MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 46.2M/1.35G [00:00<00:12, 114MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 58.4M/1.35G [00:00<00:11, 119MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 72.9M/1.35G [00:00<00:10, 129MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▋         | 87.0M/1.35G [00:00<00:10, 135MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 102M/1.35G [00:00<00:09, 142MB/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 117M/1.35G [00:00<00:08, 148MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 133M/1.35G [00:01<00:08, 152MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 147M/1.35G [00:01<00:08, 152MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 162M/1.35G [00:01<00:08, 150MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 176M/1.35G [00:01<00:08, 146MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 192M/1.35G [00:01<00:08, 150MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 206M/1.35G [00:01<00:08, 151MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 221M/1.35G [00:01<00:07, 153MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 236M/1.35G [00:01<00:07, 153MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 250M/1.35G [00:01<00:08, 132MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 265M/1.35G [00:01<00:08, 139MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 279M/1.35G [00:02<00:08, 132MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 292M/1.35G [00:02<00:09, 126MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 304M/1.35G [00:02<00:09, 121MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 316M/1.35G [00:02<00:10, 103MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▎       | 326M/1.35G [00:02<00:11, 99.5MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 339M/1.35G [00:02<00:10, 109MB/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 350M/1.35G [00:02<00:09, 111MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 361M/1.35G [00:02<00:09, 110MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 372M/1.35G [00:03<00:09, 112MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 384M/1.35G [00:03<00:09, 114MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 395M/1.35G [00:03<00:09, 104MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 409M/1.35G [00:03<00:08, 117MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 421M/1.35G [00:03<00:08, 120MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███▏      | 433M/1.35G [00:03<00:08, 122MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 445M/1.35G [00:03<00:07, 123MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 459M/1.35G [00:03<00:07, 129MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 471M/1.35G [00:03<00:07, 121MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 488M/1.35G [00:04<00:06, 136MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▋      | 501M/1.35G [00:04<00:06, 136MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 514M/1.35G [00:04<00:06, 133MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 527M/1.35G [00:04<00:06, 132MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 540M/1.35G [00:04<00:07, 118MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 552M/1.35G [00:04<00:07, 121MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 564M/1.35G [00:04<00:07, 121MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 576M/1.35G [00:04<00:08, 102MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 586M/1.35G [00:05<00:10, 76.3MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 598M/1.35G [00:05<00:09, 86.5MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 611M/1.35G [00:05<00:08, 96.7MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 621M/1.35G [00:05<00:13, 56.9MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 633M/1.35G [00:05<00:12, 63.7MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 646M/1.35G [00:05<00:09, 77.6MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 661M/1.35G [00:06<00:08, 92.6MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 675M/1.35G [00:06<00:06, 106MB/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████▉     | 689M/1.35G [00:06<00:06, 117MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 704M/1.35G [00:06<00:05, 126MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 717M/1.35G [00:06<00:05, 129MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 731M/1.35G [00:06<00:05, 132MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 744M/1.35G [00:06<00:05, 131MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 757M/1.35G [00:06<00:06, 103MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 770M/1.35G [00:06<00:05, 110MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 783M/1.35G [00:07<00:05, 118MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 796M/1.35G [00:07<00:04, 124MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▊    | 809M/1.35G [00:07<00:05, 113MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████▉    | 822M/1.35G [00:07<00:04, 121MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 837M/1.35G [00:07<00:04, 129MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 849M/1.35G [00:07<00:05, 110MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 862M/1.35G [00:07<00:04, 116MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 874M/1.35G [00:07<00:04, 112MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 888M/1.35G [00:07<00:04, 121MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 903M/1.35G [00:08<00:03, 130MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▋   | 917M/1.35G [00:08<00:03, 135MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 932M/1.35G [00:08<00:03, 140MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▊   | 945M/1.35G [00:08<00:03, 119MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████▉   | 962M/1.35G [00:08<00:03, 132MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 977M/1.35G [00:08<00:03, 140MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 993M/1.35G [00:08<00:02, 147MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 0.98G/1.35G [00:08<00:02, 145MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 1.00G/1.35G [00:08<00:02, 150MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 1.01G/1.35G [00:09<00:02, 149MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▋  | 1.03G/1.35G [00:09<00:02, 151MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 1.04G/1.35G [00:09<00:02, 150MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 1.06G/1.35G [00:09<00:02, 106MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 1.07G/1.35G [00:09<00:02, 116MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 1.08G/1.35G [00:09<00:02, 127MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 1.10G/1.35G [00:09<00:01, 138MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 1.11G/1.35G [00:09<00:01, 140MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 1.13G/1.35G [00:09<00:01, 148MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▍ | 1.14G/1.35G [00:10<00:01, 147MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 1.16G/1.35G [00:10<00:01, 148MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 1.17G/1.35G [00:10<00:01, 142MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 1.19G/1.35G [00:10<00:01, 143MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 1.20G/1.35G [00:10<00:01, 140MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 1.21G/1.35G [00:10<00:01, 136MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 1.23G/1.35G [00:10<00:01, 113MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 1.24G/1.35G [00:10<00:00, 121MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 1.25G/1.35G [00:11<00:00, 125MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 1.26G/1.35G [00:11<00:01, 78.6MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▍| 1.28G/1.35G [00:11<00:00, 91.9MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 1.29G/1.35G [00:11<00:00, 106MB/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 1.31G/1.35G [00:11<00:00, 121MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 1.32G/1.35G [00:11<00:00, 130MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 1.34G/1.35G [00:11<00:00, 135MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 1.35G/1.35G [00:11<00:00, 121MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize the models\n",
    "summary_model, summary_vis_processors = ammico.SummaryDetector(image_dict).load_model(model_type=\"base\")\n",
    "# run the analysis without having to re-iniatialize the model\n",
    "for key in image_dict.keys():\n",
    "    image_dict[key] = ammico.SummaryDetector(image_dict[key], analysis_type=\"summary\", \n",
    "                                             summary_model=summary_model, \n",
    "                                             summary_vis_processors=summary_vis_processors).analyse_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be done in a separate loop or in the same loop as for text and emotion detection.\n",
    "\n",
    "The nested dictionary will be updated from containing only the file id's and paths to the image files, to containing also all the image data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Convert analysis output to pandas dataframe and write csv\n",
    "The content of the nested dictionary can then conveniently be converted into a pandas dataframe for further analysis in Python, or be written as a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T14:25:44.833478Z",
     "iopub.status.busy": "2023-11-13T14:25:44.833070Z",
     "iopub.status.idle": "2023-11-13T14:25:44.942238Z",
     "shell.execute_reply": "2023-11-13T14:25:44.941342Z"
    }
   },
   "outputs": [],
   "source": [
    "image_df = ammico.get_dataframe(image_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T14:25:44.948101Z",
     "iopub.status.busy": "2023-11-13T14:25:44.947371Z",
     "iopub.status.idle": "2023-11-13T14:25:45.134900Z",
     "shell.execute_reply": "2023-11-13T14:25:45.133960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>text_language</th>\n",
       "      <th>text_english</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_summary</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>entity</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>...</th>\n",
       "      <th>multiple_faces</th>\n",
       "      <th>no_faces</th>\n",
       "      <th>wears_mask</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion (category)</th>\n",
       "      <th>const_image_summary</th>\n",
       "      <th>3_non-deterministic_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/106349S_por.png</td>\n",
       "      <td>NEWS URGENTE SAMSUNG AO VIVO Rio de Janeiro NO...</td>\n",
       "      <td>pt</td>\n",
       "      <td>NEWS URGENT SAMSUNG LIVE Rio de Janeiro NEW CO...</td>\n",
       "      <td>NEWS URGENT SAMSUNG LIVE Rio de Janeiro NEW CO...</td>\n",
       "      <td>NEW COUNTING METHOD RJ City HALL EXCLUDES 1,1...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.99</td>\n",
       "      <td>[Rio de Janeiro, C, ##IT, ##Y, PLANALTO]</td>\n",
       "      <td>[LOC, ORG, LOC, ORG, LOC]</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>[Yes]</td>\n",
       "      <td>[24]</td>\n",
       "      <td>[Man]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>a man wearing a face mask while looking at a c...</td>\n",
       "      <td>[a man wearing a mask is looking at the news, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/102141_2_eng.png</td>\n",
       "      <td>CORONAVIRUS QUARANTINE CORONAVIRUS OUTBREAK BE...</td>\n",
       "      <td>en</td>\n",
       "      <td>CORONAVIRUS QUARANTINE CORONAVIRUS OUTBREAK BE...</td>\n",
       "      <td>CORONAVIRUS QUARANTINE CORONAVIRUS OUTBREAK BE...</td>\n",
       "      <td>Coronavirus QUARANTINE CORONAVIRUS OUTBREAK</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.97</td>\n",
       "      <td>[CORONAVIRUS, ##ARANTI, CORONAVIR, Co, ##ronavi]</td>\n",
       "      <td>[ORG, MISC, ORG, PER, ORG]</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>[Yes]</td>\n",
       "      <td>[25]</td>\n",
       "      <td>[Man]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>a collage of images including a corona sign, a...</td>\n",
       "      <td>[two images of corona warning, a man holding u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/102730_eng.png</td>\n",
       "      <td>400 DEATHS GET E-BOOK X AN Corporation ncy Ser...</td>\n",
       "      <td>en</td>\n",
       "      <td>400 DEATHS GET E-BOOK X AN Corporation ncy Ser...</td>\n",
       "      <td>DEATHS GET E - BOOK X AN Corporation Services ...</td>\n",
       "      <td>A municipal worker sprays disinfectant on his...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.99</td>\n",
       "      <td>[AN Corporation ncy Services, Ahmedabad, RE, #...</td>\n",
       "      <td>[ORG, LOC, PER, ORG]</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>[No]</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[Man]</td>\n",
       "      <td>[asian]</td>\n",
       "      <td>[sad]</td>\n",
       "      <td>[Negative]</td>\n",
       "      <td>two people in blue coats spray disinfection a van</td>\n",
       "      <td>[two people in blue scrub suits spraying water...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename                                               text  \\\n",
       "0   data/106349S_por.png  NEWS URGENTE SAMSUNG AO VIVO Rio de Janeiro NO...   \n",
       "1  data/102141_2_eng.png  CORONAVIRUS QUARANTINE CORONAVIRUS OUTBREAK BE...   \n",
       "2    data/102730_eng.png  400 DEATHS GET E-BOOK X AN Corporation ncy Ser...   \n",
       "\n",
       "  text_language                                       text_english  \\\n",
       "0            pt  NEWS URGENT SAMSUNG LIVE Rio de Janeiro NEW CO...   \n",
       "1            en  CORONAVIRUS QUARANTINE CORONAVIRUS OUTBREAK BE...   \n",
       "2            en  400 DEATHS GET E-BOOK X AN Corporation ncy Ser...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  NEWS URGENT SAMSUNG LIVE Rio de Janeiro NEW CO...   \n",
       "1  CORONAVIRUS QUARANTINE CORONAVIRUS OUTBREAK BE...   \n",
       "2  DEATHS GET E - BOOK X AN Corporation Services ...   \n",
       "\n",
       "                                        text_summary sentiment  \\\n",
       "0   NEW COUNTING METHOD RJ City HALL EXCLUDES 1,1...  NEGATIVE   \n",
       "1        Coronavirus QUARANTINE CORONAVIRUS OUTBREAK  NEGATIVE   \n",
       "2   A municipal worker sprays disinfectant on his...  NEGATIVE   \n",
       "\n",
       "   sentiment_score                                             entity  \\\n",
       "0             0.99           [Rio de Janeiro, C, ##IT, ##Y, PLANALTO]   \n",
       "1             0.97   [CORONAVIRUS, ##ARANTI, CORONAVIR, Co, ##ronavi]   \n",
       "2             0.99  [AN Corporation ncy Services, Ahmedabad, RE, #...   \n",
       "\n",
       "                  entity_type  ... multiple_faces no_faces  wears_mask   age  \\\n",
       "0   [LOC, ORG, LOC, ORG, LOC]  ...             No        1       [Yes]  [24]   \n",
       "1  [ORG, MISC, ORG, PER, ORG]  ...             No        1       [Yes]  [25]   \n",
       "2        [ORG, LOC, PER, ORG]  ...             No        1        [No]  [27]   \n",
       "\n",
       "  gender     race emotion emotion (category)  \\\n",
       "0  [Man]   [None]  [None]             [None]   \n",
       "1  [Man]   [None]  [None]             [None]   \n",
       "2  [Man]  [asian]   [sad]         [Negative]   \n",
       "\n",
       "                                 const_image_summary  \\\n",
       "0  a man wearing a face mask while looking at a c...   \n",
       "1  a collage of images including a corona sign, a...   \n",
       "2  two people in blue coats spray disinfection a van   \n",
       "\n",
       "                         3_non-deterministic_summary  \n",
       "0  [a man wearing a mask is looking at the news, ...  \n",
       "1  [two images of corona warning, a man holding u...  \n",
       "2  [two people in blue scrub suits spraying water...  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or write to a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T14:25:45.251373Z",
     "iopub.status.busy": "2023-11-13T14:25:45.250601Z",
     "iopub.status.idle": "2023-11-13T14:25:45.292835Z",
     "shell.execute_reply": "2023-11-13T14:25:45.292075Z"
    }
   },
   "outputs": [],
   "source": [
    "image_df.to_csv(\"data_out.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The detector modules\n",
    "The different detector modules with their options are explained in more detail in this section.\n",
    "## Text detector\n",
    "Text on the images can be extracted using the `TextDetector` class (`text` module). The text is initally extracted using the Google Cloud Vision API and then translated into English with googletrans. The translated text is cleaned of whitespace, linebreaks, and numbers using Python syntax and spaCy. \n",
    "\n",
    "<img src=\"../_static/text_detector.png\" width=\"800\" />\n",
    "\n",
    "The user can set if the text should be further summarized, and analyzed for sentiment and named entity recognition, by setting the keyword `analyse_text` to `True` (the default is `False`). If set, the transformers pipeline is used for each of these tasks, with the default models as of 03/2023. Other models can be selected by setting the optional keyword `model_names` to a list of selected models, on for each task: `model_names=[\"sshleifer/distilbart-cnn-12-6\", \"distilbert-base-uncased-finetuned-sst-2-english\", \"dbmdz/bert-large-cased-finetuned-conll03-english\"]` for summary, sentiment, and ner. To be even more specific, revision numbers can also be selected by specifying the optional keyword `revision_numbers` to a list of revision numbers for each model, for example `revision_numbers=[\"a4f8f3e\", \"af0f99b\", \"f2482bf\"]`. \n",
    "\n",
    "Please note that for the Google Cloud Vision API (the TextDetector class) you need to set a key in order to process the images. This key is ideally set as an environment variable using for example:\n",
    "\n",
    "`os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"misinformation-campaign-981aa55a3b13.json\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where you place the key on your Google Drive if running on colab, or place it in a local folder on your machine.\n",
    "\n",
    "Summarizing, the text detection is carried out using the following method call and keywords, where `analyse_text`, `model_names`, and `revision_numbers` are optional:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T14:25:45.297990Z",
     "iopub.status.busy": "2023-11-13T14:25:45.297297Z",
     "iopub.status.idle": "2023-11-13T14:27:04.123003Z",
     "shell.execute_reply": "2023-11-13T14:27:04.121173Z"
    }
   },
   "outputs": [],
   "source": [
    "for key in image_dict.keys():\n",
    "    image_dict[key] = ammico.TextDetector(image_dict[key], \n",
    "    analyse_text=True, model_names=[\"sshleifer/distilbart-cnn-12-6\", \n",
    "    \"distilbert-base-uncased-finetuned-sst-2-english\", \n",
    "    \"dbmdz/bert-large-cased-finetuned-conll03-english\"], \n",
    "    revision_numbers=[\"a4f8f3e\", \"af0f99b\", \"f2482bf\"]).analyse_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models can be adapted interactively in the notebook interface and the best models can then be used in a subsequent analysis of the whole data set.\n",
    "\n",
    "A detailed description of the output keys and data types is given in the following table.\n",
    "\n",
    "| output key | output type | output value |\n",
    "| ---------- | ----------- | ------------ |\n",
    "| `text` | `str` | the extracted text in the original language |\n",
    "| `text_language` | `str` | the detected dominant language of the extracted text |\n",
    "| `text_english` | `str` | the text translated into English |\n",
    "| `text_clean` | `str` | the text after cleaning from numbers and unrecognizable words |\n",
    "| `text_summary` | `str` | the summary of the text, generated with a transformers model |\n",
    "| `sentiment` | `str` | the detected sentiment, generated with a transformers model |\n",
    "| `sentiment_score` | `float` | the confidence associated with the predicted sentiment |\n",
    "| `entity` | `list[str]` | the detected named entities, generated with a transformers model |\n",
    "| `entity_type` | `list[str]` | the detected entity type |\n",
    "\n",
    "## Image summary and query\n",
    "\n",
    "The `SummaryDetector` can be used to generate image captions (`summary`) as well as visual question answering (`VQA`). \n",
    "\n",
    "<img src=\"../_static/summary_detector.png\" width=\"800\" />\n",
    "\n",
    "This module is based on the [LAVIS](https://github.com/salesforce/LAVIS) library. Since the models can be quite large, an initial object is created which will load the necessary models into RAM/VRAM and then use them in the analysis. The user can specify the type of analysis to be performed using the `analysis_type` keyword. Setting it to `summary` will generate a caption (summary), `questions` will prepare answers (VQA) to a list of questions as set by the user, `summary_and_questions` will do both. Note that the desired analysis type needs to be set here in the initialization of the \n",
    "detector object, and not when running the analysis for each image; the same holds true for the selected model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T14:27:04.132034Z",
     "iopub.status.busy": "2023-11-13T14:27:04.131358Z",
     "iopub.status.idle": "2023-11-13T14:27:22.574096Z",
     "shell.execute_reply": "2023-11-13T14:27:22.573248Z"
    }
   },
   "outputs": [],
   "source": [
    "image_summary_detector = ammico.SummaryDetector(image_dict, analysis_type=\"summary\", model_type=\"base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implemented models are listed below.\n",
    "\n",
    "| input model name | model |\n",
    "| ---------------- | ----- |\n",
    "| base | BLIP image captioning base, ViT-B/16, pretrained on COCO dataset |\n",
    "| large | BLIP image captioning large, ViT-L/16, pretrained on COCO dataset |\n",
    "| vqa | BLIP base model fine-tuned on VQA v2.0 dataset |\n",
    "| blip2_t5_pretrain_flant5xxl | BLIP2 pretrained on FlanT5<sub>XXL</sub> | \n",
    "| blip2_t5_pretrain_flant5xl | BLIP2 pretrained on FlanT5<sub>XL</sub> | \n",
    "| blip2_t5_caption_coco_flant5xl | BLIP2 pretrained on FlanT5<sub>XL</sub>, fine-tuned on COCO | \n",
    "| blip2_opt_pretrain_opt2.7b | BLIP2 pretrained on OPT-2.7b |\n",
    "| blip2_opt_pretrain_opt6.7b | BLIP2 pretrained on OPT-6.7b | \n",
    "| blip2_opt_caption_coco_opt2.7b | BLIP2 pretrained on OPT-2.7b, fine-tuned on COCO | \n",
    "| blip2_opt_caption_coco_opt6.7b | BLIP2 pretrained on OPT-6.7b, fine-tuned on COCO |\n",
    "\n",
    "For VQA, a list of questions needs to be passed when carrying out the analysis; these should be given as a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T14:27:22.581638Z",
     "iopub.status.busy": "2023-11-13T14:27:22.581075Z",
     "iopub.status.idle": "2023-11-13T14:27:22.585037Z",
     "shell.execute_reply": "2023-11-13T14:27:22.584391Z"
    }
   },
   "outputs": [],
   "source": [
    "list_of_questions = [\n",
    "    \"How many persons on the picture?\",\n",
    "    \"Are there any politicians in the picture?\",\n",
    "    \"Does the picture show something from medicine?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing, the detector is run as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T14:27:22.593652Z",
     "iopub.status.busy": "2023-11-13T14:27:22.593122Z",
     "iopub.status.idle": "2023-11-13T14:29:10.348633Z",
     "shell.execute_reply": "2023-11-13T14:29:10.346293Z"
    }
   },
   "outputs": [],
   "source": [
    "image_summary_vqa_detector = ammico.SummaryDetector(image_dict, analysis_type=\"summary_and_questions\", \n",
    "                                                    model_type=\"base\")\n",
    "for key in image_dict.keys():\n",
    "    image_dict[key] = image_summary_vqa_detector.analyse_image(image_dict[key], \n",
    "                                                               list_of_questions = list_of_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is given as a dictionary with the following keys and data types:\n",
    "\n",
    "| output key | output type | output value |\n",
    "| ---------- | ----------- | ------------ |\n",
    "| `const_image_summary` | `str` | when `analysis_type=\"summary\"` or `\"summary_and_questions\"`, constant image caption (does not change upon re-running the analysis for the same model) |\n",
    "| `3_non-deterministic_summary` | `list[str]` | when `analysis_type=\"summary\"` or s`ummary_and_questions`, three different captions generated with different random seeds |\n",
    "| *a user-defined input question* | `str` | when `analysis_type=\"questions\"` or `summary_and_questions`, the answer to the user-defined input question | \n",
    "\n",
    "## Detection of faces and facial expression analysis\n",
    "Faces and facial expressions are detected and analyzed using the `EmotionDetector` class from the `faces` module. Initially, it is detected if faces are present on the image using RetinaFace, followed by analysis if face masks are worn (Face-Mask-Detection). The detection of age, gender, race, and emotions is carried out with deepface.\n",
    "\n",
    "<img src=\"../_static/emotion_detector.png\" width=\"800\" />\n",
    "\n",
    "Depending on the features found on the image, the face detection module returns a different analysis content: If no faces are found on the image, all further steps are skipped and the result `\"face\": \"No\", \"multiple_faces\": \"No\", \"no_faces\": 0, \"wears_mask\": [\"No\"], \"age\": [None], \"gender\": [None], \"race\": [None], \"emotion\": [None], \"emotion (category)\": [None]` is returned. If one or several faces are found, up to three faces are analyzed if they are partially concealed by a face mask. If yes, only age and gender are detected; if no, also race, emotion, and dominant emotion are detected. In case of the latter, the output could look like this: `\"face\": \"Yes\", \"multiple_faces\": \"Yes\", \"no_faces\": 2, \"wears_mask\": [\"No\", \"No\"], \"age\": [27, 28], \"gender\": [\"Man\", \"Man\"], \"race\": [\"asian\", None], \"emotion\": [\"angry\", \"neutral\"], \"emotion (category)\": [\"Negative\", \"Neutral\"]`, where for the two faces that are detected (given by `no_faces`), some of the values are returned as a list with the first item for the first (largest) face and the second item for the second (smaller) face (for example, `\"emotion\"` returns a list `[\"angry\", \"neutral\"]` signifying the first face expressing anger, and the second face having a neutral expression).\n",
    "\n",
    "The emotion detection reports the seven facial expressions angry, fear, neutral, sad, disgust, happy and surprise. These emotions are assigned based on the returned confidence of the model (between 0 and 1), with a high confidence signifying a high likelihood of the detected emotion being correct. Emotion recognition is not an easy task, even for a human; therefore, we have added a keyword `emotion_threshold` signifying the % value above which an emotion is counted as being detected. The default is set to 50%, so that a confidence above 0.5 results in an emotion being assigned. If the confidence is lower, no emotion is assigned. \n",
    "\n",
    "From the seven facial expressions, an overall dominating emotion category is identified: negative, positive, or neutral emotion. These are defined with the facial expressions angry, disgust, fear and sad for the negative category, happy for the positive category, and surprise and neutral for the neutral category.\n",
    "\n",
    "A similar threshold as for the emotion recognition is set for the race detection, `race_threshold`, with the default set to 50% so that a confidence for the race above 0.5 only will return a value in the analysis. \n",
    "\n",
    "Summarizing, the face detection is carried out using the following method call and keywords, where `emotion_threshold` and \n",
    "`race_threshold` are optional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T14:29:10.425663Z",
     "iopub.status.busy": "2023-11-13T14:29:10.422643Z",
     "iopub.status.idle": "2023-11-13T14:30:58.690969Z",
     "shell.execute_reply": "2023-11-13T14:30:58.689781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 1s 979ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 18s 18s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 20s 20s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 1s 748ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 246ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 201ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 1s 739ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 352ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 229ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 22s 22s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 110ms/step\n"
     ]
    }
   ],
   "source": [
    "for key in image_dict.keys():\n",
    "    image_dict[key] = ammico.EmotionDetector(image_dict[key], emotion_threshold=50, race_threshold=50).analyse_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thresholds can be adapted interactively in the notebook interface and the optimal value can then be used in a subsequent analysis of the whole data set.\n",
    "\n",
    "The output keys that are generated are\n",
    "\n",
    "| output key | output type | output value |\n",
    "| ---------- | ----------- | ------------ |\n",
    "| `face` | `str` | if a face is detected |\n",
    "| `multiple_faces` | `str` | if multiple faces are detected |\n",
    "| `no_faces` | `int` | the number of detected faces |\n",
    "| `wears_mask` | `list[str]` | if each of the detected faces wears a face covering, up to three faces |\n",
    "| `age` | `list[int]` | the detected age, up to three faces |\n",
    "| `gender` | `list[str]` | the detected gender, up to three faces |\n",
    "| `race` | `list[str]` | the detected race, up to three faces, if above the confidence threshold |\n",
    "| `emotion` | `list[str]` | the detected emotion, up to three faces, if above the confidence threshold |\n",
    "| `emotion (category)` | `list[str]` | the detected emotion category (positive, negative, or neutral), up to three faces, if above the confidence threshold |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further detector modules\n",
    "Further detector modules exist, such as `ColorDetector` and `MultimodalSearch`, also it is possible to carry out a topic analysis on the text data, as well as crop social media posts automatically. These are more experimental features and have their own demonstration notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ammico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
